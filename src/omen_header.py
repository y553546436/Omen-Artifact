import argparse
import torch
import pickle
import numpy as np
import math
from string import Template
from utils import tensor_to_c_array


def generate_header(args, data_dir):
    torch.manual_seed(0)
    np.random.seed(0)
    with open(f'{data_dir}/testlbl.pkl', 'rb') as f:
        testlbl = np.array(pickle.load(f))
    with open(f'{data_dir}/model.pkl', 'rb') as f:
        model = np.array(pickle.load(f))
    dataset, start, alpha = args.dataset, int(args.start), float(args.alpha)
    freq = int(args.freq)
    assert start % freq == 0, 'start must be multiple of freq'
    num_class = model.shape[0]
    dim = model.shape[-1]
    print('Model shape:', model.shape)
    # import the load function from the {dataset}.py file
    load = getattr(__import__(dataset), 'load')
    if not callable(load):
        raise ValueError(f'load function not found in {dataset}.py')

    print('Loading...')
    x, x_test, y, y_test = load()
    num_features = x.size(1) if args.dataset != 'language' else max(len(s) for s in x_test+x)
    num_test = len(testlbl)

    # generate threshold data
    threshold_data = np.zeros(num_class - 1)
    for i in range(num_class - 1):
        alpha_ = alpha / (i+1)
        from scipy.special import ndtri
        threshold_data[i] = ndtri(1 - alpha_) ** 2

    # calculate diff2 data
    class_hv = torch.tensor(model)
    pair_diff = class_hv.unsqueeze(1) != class_hv.unsqueeze(0)
    diff2 = torch.cumsum(pair_diff, dim=-1).int()
    test_locs = torch.arange(freq-1, dim, freq)
    if test_locs[-1] != dim-1:
        test_locs = torch.cat((test_locs, torch.tensor([dim-1])))
    diff2_data = diff2[:, :, test_locs].cpu().numpy()
    diff2_data = np.transpose(diff2_data, (0, 2, 1))
    assert diff2_data.shape == (num_class, int(math.ceil(dim/freq)), num_class), f'diff2_data shape: {diff2_data.shape}, expected: {(num_class, int(dim/freq), num_class)}'

    # read thresholds data for diff, absolute and mean strategies
    with open(f'{data_dir}/diff_threshold.pkl', 'rb') as f:
        diff_threshold = pickle.load(f)
    with open(f'{data_dir}/absolute_threshold.pkl', 'rb') as f:
        absolute_threshold = pickle.load(f)
    with open(f'{data_dir}/mean_thresholds.pkl', 'rb') as f:
        mean_thresholds = pickle.load(f)

    # check data shapes
    assert x_test.shape == (num_test, num_features), f'x_test shape: {x_test.shape}, expected: {(num_test, num_features)}'
    assert threshold_data.shape == (num_class - 1,), f'threshold_data shape: {threshold_data.shape}, expected: {(num_class - 1,)}'

    # write to header file
    header = """ // This file is generated by omen_header.py
#ifndef OMEN_H
#define OMEN_H

#include <stdint.h>

#define $data_type

#define NUMFEATURE $num_feature
#define NUMCLASS $num_class
#define BUFFER_SIZE NUMFEATURE * sizeof(float)

#ifndef FREQ
#define FREQ $freq
#endif
#ifndef START
#define START $start
#endif

extern float TEST_FEATURE[NUMFEATURE];


#define __ceildiv(a, b) (((a) + (b) - 1) / (b))

const double THRESHOLD[$num_class - 1] = $threshold_data;

const int DIFF2[$num_class][__ceildiv($num_dim, FREQ)][$num_class] = $diff2_data;

// for other strategies
#define DIFF_THRESHOLD $diff_threshold
#define ABSOLUTE_THRESHOLD $absolute_threshold
const double MEAN_THRESHOLD[NUMCLASS] = $mean_thresholds;

#endif
"""
    data_mapping = {
        'start': start,
        'freq': freq,
        'num_feature': num_features,
        'num_dim': dim,
        'num_class': num_class,
        'data_type': 'BINARY',
        'threshold_data': threshold_data,
        'diff2_data': diff2_data,
        'diff_threshold': diff_threshold,
        'absolute_threshold': absolute_threshold,
        'mean_thresholds': mean_thresholds,
    }
    shapes = {
        'start': data_mapping['start'],
        'freq': data_mapping['freq'],
        'num_feature': data_mapping['num_feature'],
        'num_dim': data_mapping['num_dim'],
        'num_class': data_mapping['num_class'],
        'data_type': data_mapping['data_type'],
        'threshold_data': data_mapping['threshold_data'].shape,
        'diff2_data': data_mapping['diff2_data'].shape,
        'diff_threshold': data_mapping['diff_threshold'],
        'absolute_threshold': data_mapping['absolute_threshold'],
        'mean_thresholds': data_mapping['mean_thresholds'].shape,
    }
    print('Shapes:', shapes)
    string_mapping = {
        'start': str(data_mapping['start']),
        'freq': str(data_mapping['freq']),
        'num_feature': str(data_mapping['num_feature']),
        'num_dim': str(data_mapping['num_dim']),
        'num_class': str(data_mapping['num_class']),
        'data_type': data_mapping['data_type'],
        'threshold_data': tensor_to_c_array(data_mapping['threshold_data']),
        'diff2_data': tensor_to_c_array(data_mapping['diff2_data']),
        'diff_threshold': str(data_mapping['diff_threshold']),
        'absolute_threshold': str(data_mapping['absolute_threshold']),
        'mean_thresholds': tensor_to_c_array(data_mapping['mean_thresholds']),
    }
    header = Template(header).substitute(string_mapping)
    return header


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Estimate performance of Omen')
    parser.add_argument('--dataset', type=str, help='Dataset name: mnist, isolet, ucihar')
    parser.add_argument('--data', type=str, help='Directory containing model and test data')
    parser.add_argument('--alpha', type=str, help='Omen confidence threshold alpha')
    parser.add_argument('--start', type=str, help='First dimension Omen conducts a test')
    parser.add_argument('--freq', type=str, help='Interval between two consecutive tests (linear), or ratio between two consecutive tests (exponential)')
    parser.add_argument('--output', type=str, help='Path to save the generated header file', required=True)
    args = parser.parse_args()
    if args.dataset == 'language' and not args.binary:
        raise ValueError('Language dataset must use binary hypervectors')
    if args.alpha is None:
        args.alpha = '0.05' # default confidence threshold
    if args.data is None and args.dataset is not None:
        args.data = f'data-{args.dataset}'
    if args.data is None and args.dataset is None:
        print('Using default data directory: data')
        args.data = 'data'
    print('Output header file will be saved at', args.output)
    with open(args.output, 'w') as f:
        f.write(generate_header(args, args.data))
